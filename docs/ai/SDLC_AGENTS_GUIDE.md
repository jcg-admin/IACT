# Gu√≠a de Uso: Agentes SDLC con LLM

Esta gu√≠a explica c√≥mo usar los agentes SDLC (Software Development Life Cycle) que han sido integrados con capacidades de LLM (Large Language Models).

## üìã Tabla de Contenidos

1. [Descripci√≥n General](#descripci√≥n-general)
2. [Configuraci√≥n](#configuraci√≥n)
3. [Agentes Disponibles](#agentes-disponibles)
4. [Uso B√°sico](#uso-b√°sico)
5. [Ejemplos Avanzados](#ejemplos-avanzados)
6. [Troubleshooting](#troubleshooting)

---

## üéØ Descripci√≥n General

Los agentes SDLC automatizan cada fase del ciclo de desarrollo de software, desde la evaluaci√≥n de viabilidad hasta el despliegue. Cada agente puede operar en dos modos:

- **Modo Heur√≠stico**: An√°lisis basado en reglas (r√°pido, determinista, sin costo)
- **Modo LLM**: An√°lisis potenciado por IA (inteligente, contextual, requiere API/modelo local)

**Ventajas del Modo LLM:**
- An√°lisis m√°s profundo y contextual
- Recomendaciones m√°s espec√≠ficas
- Identificaci√≥n de riesgos sutiles
- Mejor comprensi√≥n de requisitos ambiguos

---

## ‚öôÔ∏è Configuraci√≥n

### Opci√≥n 1: Anthropic Claude (Nube)

```python
config = {
    "llm_provider": "anthropic",
    "model": "claude-3-5-sonnet-20241022",
    "use_llm": True
}

# Configurar API key (en .env o environment)
export ANTHROPIC_API_KEY="tu-api-key"
```

**Pros:** Mejor calidad, r√°pido, confiable
**Cons:** Requiere API key ($), env√≠a datos a la nube

### Opci√≥n 2: OpenAI GPT-4 (Nube)

```python
config = {
    "llm_provider": "openai",
    "model": "gpt-4-turbo-preview",
    "use_llm": True
}

# Configurar API key
export OPENAI_API_KEY="tu-api-key"
```

**Pros:** Excelente calidad, bien documentado
**Cons:** M√°s costoso que Claude, env√≠a datos a la nube

### Opci√≥n 3: Ollama (Local, Open Source) - RECOMENDADO

```python
config = {
    "llm_provider": "ollama",
    "model": "qwen2.5-coder:32b",  # o "llama3.1:8b", "deepseek-coder-v2"
    "ollama_base_url": "http://localhost:11434",  # opcional
    "use_llm": True
}

# Instalar y ejecutar Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama serve

# Descargar modelo
ollama pull qwen2.5-coder:32b
```

**Pros:** Gratis, privado, sin l√≠mites de uso
**Cons:** Requiere hardware (32GB+ RAM recomendado), m√°s lento que APIs cloud

### Modo Sin LLM (Solo Heur√≠sticas)

```python
config = {
    "use_llm": False  # o simplemente config=None
}
```

**Pros:** R√°pido, no requiere configuraci√≥n
**Cons:** An√°lisis m√°s b√°sico

---

## ü§ñ Agentes Disponibles

### 1. SDLCFeasibilityAgent

**Prop√≥sito:** Eval√∫a la viabilidad t√©cnica de una feature antes de implementarla.

**Analiza:**
- Viabilidad t√©cnica (complejidad, dependencias, compatibilidad)
- Riesgos (t√©cnicos, de recursos, de calendario)
- Esfuerzo estimado (story points, personas, duraci√≥n)

**Decisi√≥n:** GO / NO-GO / REVIEW

**Uso:**
```python
from scripts.ai.sdlc.feasibility_agent import SDLCFeasibilityAgent

# Con LLM
config = {"llm_provider": "ollama", "model": "qwen2.5-coder:32b", "use_llm": True}
agent = SDLCFeasibilityAgent(config=config)

result = agent.run({
    "issue": {
        "title": "Implement JWT authentication",
        "description": "Add JWT-based auth with refresh tokens...",
        "requirements": ["Secure token storage", "Token refresh", "Logout"],
        "acceptance_criteria": ["Tokens expire after 1h", "Refresh works"],
        "estimated_story_points": 5
    }
})

print(f"Decision: {result.decision}")  # "go", "no-go", "review"
print(f"Confidence: {result.confidence}")  # 0.0 - 1.0
print(f"Risks: {result.risks}")
print(f"Method: {result.phase_result['analysis_method']}")  # "llm" o "heuristic"
```

**Output Artifacts:**
- `docs/sdlc_outputs/feasibility/FEASIBILITY_REPORT_YYYYMMDD_HHMMSS.md`

---

### 2. SDLCDesignAgent

**Prop√≥sito:** Genera documentaci√≥n de dise√±o arquitect√≥nico.

**Genera:**
- HLD (High-Level Design): Arquitectura general, componentes, flujo de datos
- LLD (Low-Level Design): Estructura de clases, m√≥dulos, APIs
- Diagramas: Mermaid para visualizaci√≥n
- ADRs (Architecture Decision Records): Decisiones de dise√±o

**Uso:**
```python
from scripts.ai.sdlc.design_agent import SDLCDesignAgent

agent = SDLCDesignAgent(config=config)

result = agent.run({
    "feasibility_result": {
        "phase": "feasibility",
        "decision": "go",
        "confidence": 0.85
    },
    "issue": {
        "title": "Implement JWT authentication",
        "description": "Add JWT-based auth...",
        "requirements": ["Secure storage", "Refresh mechanism"]
    }
})

print(f"HLD: {result.artifacts[0]}")  # Path to HLD document
print(f"LLD: {result.artifacts[1]}")  # Path to LLD document
print(f"Diagrams: {result.artifacts[2]}")  # Path to diagrams
```

**Output Artifacts:**
- `docs/sdlc_outputs/design/HLD_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/design/LLD_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/design/DIAGRAMS_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/design/DESIGN_REVIEW_CHECKLIST_YYYYMMDD_HHMMSS.md`

---

### 3. SDLCTestingAgent

**Prop√≥sito:** Genera estrategia y casos de prueba.

**Genera:**
- Test Strategy: Enfoque, √°reas cr√≠ticas, distribuci√≥n de tests
- Test Cases: Unit/Integration/E2E con pasos y aserciones
- Test Pyramid: Distribuci√≥n 60% unit / 30% integration / 10% e2e
- Coverage Requirements: M√≠nimo 80-85% seg√∫n complejidad

**Uso:**
```python
from scripts.ai.sdlc.testing_agent import SDLCTestingAgent

agent = SDLCTestingAgent(config=config)

result = agent.run({
    "design_result": {
        "phase": "design",
        "decision": "go",
        "confidence": 0.9,
        "artifacts": ["docs/.../HLD.md", "docs/.../LLD.md"]
    },
    "issue": {
        "title": "Implement JWT authentication",
        "requirements": ["Secure storage", "Refresh"],
        "estimated_story_points": 5
    }
})

print(f"Test Strategy: {result.recommendations}")
print(f"Test Cases: {len(test_cases)} cases generated")
print(f"Coverage Target: {coverage_requirement}%")
```

**Output Artifacts:**
- `docs/sdlc_outputs/testing/TEST_PLAN_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/testing/TEST_CASES_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/testing/TEST_PYRAMID_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/testing/TEST_CHECKLIST_YYYYMMDD_HHMMSS.md`

---

### 4. SDLCDeploymentAgent

**Prop√≥sito:** Genera plan de despliegue y rollback.

**Genera:**
- Deployment Plan: Estrategia (rolling/blue-green/canary), pasos, tiempos
- Rollback Plan: Triggers, procedimientos, validaciones
- Checklists: Pre/Post-deployment verification
- Monitoring Plan: M√©tricas, alertas, duraci√≥n

**Uso:**
```python
from scripts.ai.sdlc.deployment_agent import SDLCDeploymentAgent

agent = SDLCDeploymentAgent(config=config)

result = agent.run({
    "testing_result": {
        "phase": "testing",
        "decision": "go",
        "confidence": 0.88
    },
    "design_result": {...},
    "issue": {...},
    "environment": "production"  # o "staging"
})

print(f"Deployment Strategy: {strategy['approach']}")
print(f"Estimated Downtime: {strategy['downtime_minutes']} minutes")
print(f"Rollback Time: {strategy['rollback_minutes']} minutes")
```

**Output Artifacts:**
- `docs/sdlc_outputs/deployment/DEPLOYMENT_PLAN_{env}_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/deployment/ROLLBACK_PLAN_{env}_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/deployment/PRE_DEPLOYMENT_CHECKLIST_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/deployment/POST_DEPLOYMENT_CHECKLIST_YYYYMMDD_HHMMSS.md`
- `docs/sdlc_outputs/deployment/MONITORING_PLAN_YYYYMMDD_HHMMSS.md`

---

### 5. SDLCOrchestratorAgent

**Prop√≥sito:** Orquesta todos los agentes SDLC en un pipeline completo.

**Coordina:**
- Planning ‚Üí Feasibility ‚Üí Design ‚Üí Testing ‚Üí Deployment
- Decisiones GO/NO-GO entre fases
- Agregaci√≥n de riesgos
- S√≠ntesis de recomendaciones

**Uso:**
```python
from scripts.ai.sdlc.orchestrator import SDLCOrchestrator

orchestrator = SDLCOrchestrator(config=config)

result = orchestrator.run({
    "feature_request": {
        "title": "Implement JWT authentication",
        "description": "Add JWT-based authentication...",
        "requirements": ["Secure storage", "Token refresh", "Logout"],
        "acceptance_criteria": ["Tokens expire", "Refresh works"],
        "estimated_story_points": 5
    },
    "start_phase": "planning",  # opcional, default="planning"
    "end_phase": "deployment",  # opcional, default="deployment"
    "skip_phases": []  # opcional, ej: ["testing"]
})

print(f"Pipeline Status: {result['final_decision']}")  # "success", "stopped"
print(f"Phases Completed: {result['phases_completed']}")
print(f"Artifacts: {result['all_artifacts']}")
print(f"Final Report: {result['report_path']}")
```

**Output Artifacts:**
- `docs/sdlc_outputs/orchestration/SDLC_PIPELINE_REPORT_YYYYMMDD_HHMMSS.md`
- Todos los artifacts de las fases individuales

---

## üìö Ejemplos Avanzados

### Pipeline Completo con Ollama

```python
from scripts.ai.sdlc.orchestrator import SDLCOrchestrator

# Configurar Ollama (local, gratis)
config = {
    "llm_provider": "ollama",
    "model": "qwen2.5-coder:32b",
    "ollama_base_url": "http://localhost:11434",
    "use_llm": True
}

orchestrator = SDLCOrchestrator(config=config)

# Feature completa
feature = {
    "title": "User Profile Management",
    "description": """
    Implement user profile management with:
    - View profile
    - Edit profile (name, email, avatar)
    - Change password
    - Delete account
    """,
    "requirements": [
        "Secure password hashing (bcrypt)",
        "Email validation",
        "Avatar upload (max 5MB)",
        "Soft delete for accounts"
    ],
    "acceptance_criteria": [
        "Users can view their profile",
        "Users can update their info",
        "Password changes require current password",
        "Account deletion is reversible within 30 days"
    ],
    "estimated_story_points": 8
}

# Ejecutar pipeline completo
result = orchestrator.run({
    "feature_request": feature,
    "start_phase": "planning",
    "end_phase": "deployment"
})

# Revisar resultados
if result['final_decision'] == 'success':
    print("‚úÖ Pipeline completado exitosamente")
    print(f"üìÑ Reporte final: {result['report_path']}")
    print(f"üì¶ Artifacts generados: {len(result['all_artifacts'])}")
    print(f"‚ö†Ô∏è  Riesgos identificados: {len(result['aggregated_risks'])}")
    print(f"üí° Recomendaciones: {len(result['recommendations'])}")
else:
    print(f"‚ùå Pipeline detenido en fase: {result['stopped_at_phase']}")
    print(f"Raz√≥n: {result['stop_reason']}")
```

### Solo Feasibility (Evaluaci√≥n R√°pida)

```python
from scripts.ai.sdlc.feasibility_agent import SDLCFeasibilityAgent

# Sin LLM (r√°pido, heur√≠sticas)
agent = SDLCFeasibilityAgent(config=None)

result = agent.run({
    "issue": {
        "title": "Add Redis caching",  # BLOCKER: IACT proh√≠be Redis
        "description": "Use Redis for session caching",
        "requirements": ["Fast caching", "Persistence"],
        "estimated_story_points": 3
    }
})

# Decision ser√° "no-go" por restricci√≥n IACT
print(f"Decision: {result.decision}")  # "no-go"
print(f"Blockers: {[r for r in result.risks if r['severity'] == 'critical']}")
# Output: [{"type": "blocker", "description": "Redis is not allowed in IACT"}]
```

### Comparar LLM vs Heur√≠sticas

```python
from scripts.ai.sdlc.feasibility_agent import SDLCFeasibilityAgent

issue = {
    "title": "Implement GraphQL API",
    "description": "Replace REST with GraphQL",
    "requirements": ["Query optimization", "Schema design"],
    "estimated_story_points": 13
}

# Con heur√≠sticas
agent_heuristic = SDLCFeasibilityAgent(config=None)
result_h = agent_heuristic.run({"issue": issue})

# Con LLM
config = {"llm_provider": "ollama", "model": "qwen2.5-coder:32b", "use_llm": True}
agent_llm = SDLCFeasibilityAgent(config=config)
result_llm = agent_llm.run({"issue": issue})

# Comparar
print(f"Heur√≠sticas - Risks: {len(result_h.risks)}, Confidence: {result_h.confidence}")
print(f"LLM - Risks: {len(result_llm.risks)}, Confidence: {result_llm.confidence}")
# LLM t√≠picamente identifica m√°s riesgos sutiles y da confianza m√°s calibrada
```

---

## üîß Troubleshooting

### Error: "No module named 'anthropic'"

**Soluci√≥n:**
```bash
pip install anthropic
# o
uv pip install --system anthropic
```

### Error: "ANTHROPIC_API_KEY not found"

**Soluci√≥n:**
```bash
# Opci√≥n 1: Variable de entorno
export ANTHROPIC_API_KEY="tu-api-key"

# Opci√≥n 2: Archivo .env
echo "ANTHROPIC_API_KEY=tu-api-key" >> .env

# Opci√≥n 3: En c√≥digo (NO recomendado para producci√≥n)
import os
os.environ["ANTHROPIC_API_KEY"] = "tu-api-key"
```

### Error: "Connection refused" (Ollama)

**Soluci√≥n:**
```bash
# 1. Verificar que Ollama est√© instalado
ollama --version

# 2. Iniciar servidor
ollama serve

# 3. Verificar que est√© corriendo
curl http://localhost:11434/api/tags

# 4. Descargar modelo si no existe
ollama pull qwen2.5-coder:32b
```

### Ollama muy lento

**Soluciones:**
1. Usar un modelo m√°s peque√±o: `llama3.1:8b` (4.7GB) en lugar de `qwen2.5-coder:32b` (19GB)
2. Agregar GPU: Ollama usa GPU autom√°ticamente si est√° disponible
3. Aumentar RAM: Modelos grandes requieren 32GB+ RAM
4. Usar modo heur√≠stico para an√°lisis r√°pidos

### LLM genera resultados inconsistentes

**Soluciones:**
1. Reducir temperature en config: `"temperature": 0.1` (m√°s determinista)
2. Usar modelo m√°s grande: mejor coherencia
3. Usar heur√≠sticas si necesitas resultados 100% reproducibles

### Tests fallan con "ModuleNotFoundError: requests"

**Soluci√≥n:**
```bash
# Instalar requests
pip install requests
# o
uv pip install --system requests

# Ejecutar tests con python3 -m pytest
python3 -m pytest tests/ai/sdlc/
```

---

## üìñ Referencias

- **C√≥digo Fuente:** `scripts/ai/sdlc/`
- **Tests:** `tests/ai/sdlc/`
- **Arquitectura:** `scripts/ai/agents/ARCHITECTURE_SDLC_AGENTS.md`
- **Ollama Docs:** https://ollama.com/docs
- **Anthropic Docs:** https://docs.anthropic.com
- **OpenAI Docs:** https://platform.openai.com/docs

---

## üéì Mejores Pr√°cticas

1. **Empieza con Heur√≠sticas:** Eval√∫a primero sin LLM para entender el baseline
2. **Usa Ollama para Desarrollo:** Gratis, privado, bueno para iterar
3. **Usa Claude/GPT para Producci√≥n:** Mejor calidad para an√°lisis cr√≠ticos
4. **Revisa los Artifacts:** Los documentos generados son el verdadero valor
5. **Itera el Config:** Experimenta con diferentes modelos y providers
6. **Combina Modos:** Usa LLM para dise√±o/feasibility, heur√≠sticas para testing
7. **Monitorea Costos:** Si usas APIs cloud, trackea llamadas
8. **Valida Salidas:** LLMs pueden alucinar, siempre revisa manualmente

---

**Versi√≥n:** 1.0
**√öltima Actualizaci√≥n:** 2025-01-12
**Mantenedor:** Equipo IACT AI
