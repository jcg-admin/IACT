#!/usr/bin/env python3
"""
Ejemplo: Comparaci√≥n de Proveedores LLM

Este script compara el an√°lisis de la misma feature usando:
1. Heur√≠sticas (sin LLM)
2. Ollama (local, open source)
3. Anthropic Claude (nube)
4. OpenAI GPT-4 (nube)

√ötil para evaluar qu√© proveedor funciona mejor para tu caso de uso.

Uso:
    # Solo heur√≠sticas y Ollama (no requiere API keys)
    python3 examples/sdlc_compare_providers.py

    # Incluir Claude y GPT-4 (requiere API keys en .env)
    export ANTHROPIC_API_KEY="..."
    export OPENAI_API_KEY="..."
    python3 examples/sdlc_compare_providers.py --all
"""

import sys
import os
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.ai.sdlc.feasibility_agent import SDLCFeasibilityAgent


def analyze_with_provider(provider_name, config, issue):
    """
    Analiza una issue con un proveedor espec√≠fico.

    Returns:
        tuple: (result, duration_seconds, error)
    """
    print(f"\n{'‚îÄ'*70}")
    print(f"üîç Analizando con: {provider_name}")
    print(f"{'‚îÄ'*70}")

    try:
        start_time = time.time()

        agent = SDLCFeasibilityAgent(config=config)
        result = agent.run({"issue": issue})

        duration = time.time() - start_time

        print(f"‚úÖ Completado en {duration:.2f}s")

        return result, duration, None

    except Exception as e:
        duration = time.time() - start_time
        print(f"‚ùå Error: {e}")
        return None, duration, str(e)


def main():
    """Compara proveedores LLM en la misma feature."""

    # Feature de complejidad media para comparar
    issue = {
        "title": "Implement Two-Factor Authentication (2FA)",
        "description": """
        Add two-factor authentication using TOTP (Time-based One-Time Password).
        Users should be able to enable/disable 2FA in their profile settings.

        Flow:
        1. User enables 2FA in settings
        2. System generates QR code with secret
        3. User scans QR code with authenticator app (Google Authenticator, Authy)
        4. User enters 6-digit code to confirm
        5. On subsequent logins, user must provide 6-digit code after password

        Security requirements:
        - Store secret encrypted in database
        - Generate backup codes (10 single-use codes)
        - Allow 2FA reset via email (with security review)
        - Rate limit 2FA verification attempts
        """,
        "requirements": [
            "TOTP library integration (pyotp)",
            "QR code generation",
            "Encrypted secret storage",
            "Backup codes generation (10 codes)",
            "2FA verification middleware",
            "Email-based 2FA reset",
            "Rate limiting (max 3 attempts per 5 minutes)",
            "Admin panel to disable 2FA for users (emergency)"
        ],
        "acceptance_criteria": [
            "Users can enable 2FA with QR code",
            "Users can disable 2FA with current 2FA code",
            "Backup codes work for login",
            "Invalid 2FA codes are rejected",
            "Rate limiting prevents brute force",
            "Email reset works with security confirmation",
            "Tests coverage >85%"
        ],
        "estimated_story_points": 8
    }

    print("\n" + "="*70)
    print("üî¨ COMPARACI√ìN DE PROVEEDORES LLM")
    print("="*70)
    print(f"\nüìã Feature: {issue['title']}")
    print(f"üìä Story Points: {issue['estimated_story_points']}")
    print(f"üìù Requirements: {len(issue['requirements'])}")
    print(f"‚úÖ Acceptance Criteria: {len(issue['acceptance_criteria'])}")

    results = {}

    # 1. Heur√≠sticas (sin LLM) - SIEMPRE disponible
    print("\n" + "="*70)
    print("1Ô∏è‚É£  HEUR√çSTICAS (Sin LLM)")
    print("="*70)
    print("üí∞ Costo: Gratis")
    print("üåê Privacidad: Total (local)")
    print("‚ö° Velocidad: Muy r√°pida")

    result, duration, error = analyze_with_provider(
        "Heur√≠sticas",
        config=None,
        issue=issue
    )
    results['heuristic'] = (result, duration, error)

    # 2. Ollama (local) - Disponible si Ollama est√° corriendo
    print("\n" + "="*70)
    print("2Ô∏è‚É£  OLLAMA (Local Open Source)")
    print("="*70)
    print("üí∞ Costo: Gratis")
    print("üåê Privacidad: Total (local)")
    print("‚ö° Velocidad: Media-Lenta (depende de hardware)")
    print("üñ•Ô∏è  Modelo: llama3.1:8b")

    ollama_config = {
        "llm_provider": "ollama",
        "model": "llama3.1:8b",
        "ollama_base_url": "http://localhost:11434",
        "use_llm": True
    }

    result, duration, error = analyze_with_provider(
        "Ollama (llama3.1:8b)",
        config=ollama_config,
        issue=issue
    )
    results['ollama'] = (result, duration, error)

    # 3. Anthropic Claude - Solo si API key est√° disponible
    if os.getenv("ANTHROPIC_API_KEY") and "--all" in sys.argv:
        print("\n" + "="*70)
        print("3Ô∏è‚É£  ANTHROPIC CLAUDE")
        print("="*70)
        print("üí∞ Costo: ~$0.003 por request")
        print("üåê Privacidad: Cloud (Anthropic)")
        print("‚ö° Velocidad: R√°pida")
        print("ü§ñ Modelo: claude-3-5-sonnet")

        claude_config = {
            "llm_provider": "anthropic",
            "model": "claude-3-5-sonnet-20241022",
            "use_llm": True
        }

        result, duration, error = analyze_with_provider(
            "Anthropic Claude",
            config=claude_config,
            issue=issue
        )
        results['anthropic'] = (result, duration, error)
    else:
        print("\n" + "="*70)
        print("3Ô∏è‚É£  ANTHROPIC CLAUDE - SKIPPED")
        print("="*70)
        print("‚ÑπÔ∏è  Set ANTHROPIC_API_KEY y ejecuta con --all para incluir")

    # 4. OpenAI GPT-4 - Solo si API key est√° disponible
    if os.getenv("OPENAI_API_KEY") and "--all" in sys.argv:
        print("\n" + "="*70)
        print("4Ô∏è‚É£  OPENAI GPT-4")
        print("="*70)
        print("üí∞ Costo: ~$0.005 por request")
        print("üåê Privacidad: Cloud (OpenAI)")
        print("‚ö° Velocidad: R√°pida")
        print("ü§ñ Modelo: gpt-4-turbo")

        openai_config = {
            "llm_provider": "openai",
            "model": "gpt-4-turbo-preview",
            "use_llm": True
        }

        result, duration, error = analyze_with_provider(
            "OpenAI GPT-4",
            config=openai_config,
            issue=issue
        )
        results['openai'] = (result, duration, error)
    else:
        print("\n" + "="*70)
        print("4Ô∏è‚É£  OPENAI GPT-4 - SKIPPED")
        print("="*70)
        print("‚ÑπÔ∏è  Set OPENAI_API_KEY y ejecuta con --all para incluir")

    # COMPARACI√ìN DE RESULTADOS
    print("\n" + "="*70)
    print("üìä TABLA COMPARATIVA")
    print("="*70 + "\n")

    # Header
    print(f"{'Proveedor':<20} {'Decisi√≥n':<12} {'Conf.':<8} {'Riesgos':<10} "
          f"{'Tiempo':<10} {'Status'}")
    print("‚îÄ" * 80)

    # Rows
    provider_names = {
        'heuristic': 'Heur√≠sticas',
        'ollama': 'Ollama (llama3.1)',
        'anthropic': 'Anthropic Claude',
        'openai': 'OpenAI GPT-4'
    }

    for key, name in provider_names.items():
        if key in results:
            result, duration, error = results[key]

            if result:
                decision = result.decision.upper()
                confidence = f"{result.confidence:.1%}"
                num_risks = len(result.risks)
                time_str = f"{duration:.2f}s"
                status = "‚úÖ"

                # Color coding for decision
                if decision == "GO":
                    decision_display = f"‚úÖ {decision}"
                elif decision == "NO-GO":
                    decision_display = f"‚ùå {decision}"
                else:
                    decision_display = f"‚ö†Ô∏è {decision}"

                print(f"{name:<20} {decision_display:<12} {confidence:<8} "
                      f"{num_risks:<10} {time_str:<10} {status}")
            else:
                print(f"{name:<20} {'ERROR':<12} {'N/A':<8} {'N/A':<10} "
                      f"{duration:.2f}s {'‚ùå':<10} {error[:30]}")

    # AN√ÅLISIS DETALLADO DE DIFERENCIAS
    print("\n" + "="*70)
    print("üîç AN√ÅLISIS DETALLADO")
    print("="*70 + "\n")

    # Comparar n√∫mero de riesgos identificados
    print("‚ö†Ô∏è  Riesgos Identificados:")
    for key, name in provider_names.items():
        if key in results and results[key][0]:
            result = results[key][0]
            risks_by_severity = {}
            for risk in result.risks:
                sev = risk.get('severity', 'unknown')
                risks_by_severity[sev] = risks_by_severity.get(sev, 0) + 1

            risk_str = ", ".join([f"{sev}: {count}" for sev, count in risks_by_severity.items()])
            print(f"   {name:<20} ‚Üí Total: {len(result.risks):2d} ({risk_str})")

    # Comparar confianza
    print("\nüéØ Niveles de Confianza:")
    for key, name in provider_names.items():
        if key in results and results[key][0]:
            result = results[key][0]
            conf = result.confidence
            bar = "‚ñà" * int(conf * 20)
            print(f"   {name:<20} ‚Üí {conf:.1%} {bar}")

    # Comparar velocidad
    print("\n‚ö° Velocidad de An√°lisis:")
    for key, name in provider_names.items():
        if key in results and results[key][1]:
            duration = results[key][1]
            bar_len = min(int(duration / 0.5), 50)  # 0.5s por bloque
            bar = "‚ñà" * bar_len
            print(f"   {name:<20} ‚Üí {duration:5.2f}s {bar}")

    # Recomendaciones
    print("\n" + "="*70)
    print("üí° RECOMENDACIONES")
    print("="*70 + "\n")

    print("‚úÖ Usa HEUR√çSTICAS si:")
    print("   - Necesitas an√°lisis instant√°neo (<0.1s)")
    print("   - La feature es simple y bien definida")
    print("   - No tienes acceso a LLM o API keys")
    print("   - Quieres an√°lisis 100% reproducible")

    print("\n‚úÖ Usa OLLAMA si:")
    print("   - Quieres an√°lisis mejorado sin costo")
    print("   - Tienes hardware decente (16GB+ RAM)")
    print("   - Privacidad es cr√≠tica (no enviar datos a cloud)")
    print("   - Est√°s en desarrollo/testing")

    print("\n‚úÖ Usa CLAUDE si:")
    print("   - Necesitas el mejor an√°lisis posible")
    print("   - La feature es compleja o ambigua")
    print("   - Presupuesto permite ($0.003/request)")
    print("   - Velocidad es importante")

    print("\n‚úÖ Usa GPT-4 si:")
    print("   - Ya tienes infraestructura OpenAI")
    print("   - Quieres an√°lisis muy detallado")
    print("   - Presupuesto permite ($0.005/request)")

    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    main()
